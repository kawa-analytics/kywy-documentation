{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9adb4ef4-39e0-4093-9f34-70f1774eb1d4",
   "metadata": {},
   "source": [
    "# Compute Volatility vol20 and vol40 using Python columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89f7f87-8ac6-48b7-b616-714fcee8309d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from kywy.client.kawa_client import KawaClient as K\n",
    "\n",
    "kawa = K.load_client_from_environment()\n",
    "cmd = kawa.commands"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "852af24b-1ae5-419b-986d-97e5f9a1d238",
   "metadata": {},
   "source": [
    "## 1. Dataset generation\n",
    "\n",
    "Let's generate a PnL timeseries with the following dimensions:\n",
    "- portfolio\n",
    "- stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1c6105-2389-4e0e-a22f-4d0c7026641f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "data = []\n",
    "\n",
    "start_date = datetime.date(2014,1,1)\n",
    "day_count = 10 * 365\n",
    "\n",
    "# Define the different stocks in fictitious portfolios\n",
    "stocks = {\n",
    "        'US_STOCKS': ['AAPL','TSLA','MSFT','NVDA','INTC','GOOG','AMZN'],\n",
    "        'EU_STOCKS': ['BP','HSBC','ING', 'LVMH']   \n",
    "}\n",
    "\n",
    "# Define the normal distribution of the PnL for each stock to generate random data\n",
    "mu_sigma_per_stock = {\n",
    "    'AAPL': (200,5.1),\n",
    "    'TSLA': (170,8.1),\n",
    "    'MSFT': (432,0.3),\n",
    "    'NVDA': (120,10.2),\n",
    "    'INTC': (30,3.5),\n",
    "    'GOOG': (178,1.5),\n",
    "    'AMZN': (187,0.5),\n",
    "    'BP': (35,0.5),\n",
    "    'HSBC': (43,0.5),\n",
    "    'ING': (17,0.5),\n",
    "    'LVMH': (158,0.5),\n",
    "}\n",
    "\n",
    "# Generate the dataframe\n",
    "for portfolio, stock_list in stocks.items():\n",
    "    for stock in stock_list:\n",
    "        mu, sigma = mu_sigma_per_stock[stock]\n",
    "        pnl_list = np.random.normal(mu, sigma, day_count)\n",
    "        index = 0\n",
    "        for date in (start_date + datetime.timedelta(n) for n in range(day_count)):        \n",
    "            data.append({\n",
    "                'portfolio':portfolio,\n",
    "                'stock':stock,\n",
    "                'date': date,\n",
    "                'pnl':pnl_list[index],       \n",
    "            })\n",
    "            index+=1\n",
    "            \n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6365a139-63b1-4436-be75-7af21d4e2660",
   "metadata": {},
   "source": [
    "## 2. Ingest the generated data into KAWA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dff1ba7-1e17-4962-9993-86a32040caf5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "loader = kawa.new_data_loader(datasource_name='PNL data', df=df)\n",
    "loader.create_datasource()\n",
    "\n",
    "loader.load_data(\n",
    "    reset_before_insert=True,\n",
    "    create_sheet=True,\n",
    "    nb_threads=2\n",
    ");\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae4beac4-8640-4f2c-a417-c84a926c8c5f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 3. Create a Python column in KAWA\n",
    "\n",
    "#### 3.a Create the Python script\n",
    "\n",
    "Open the script section from your KAWA instance and create the following script\n",
    "\n",
    "\n",
    "```python\n",
    "import logging\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from kywy.client.kawa_decorators import outputs, inputs\n",
    "\n",
    "logger = logging.getLogger('script-logger')\n",
    "\n",
    "@inputs(key=str, date=datetime.date, pnl=float)\n",
    "@outputs(vol20=float, vol40=float)\n",
    "def execute(df: pd.DataFrame):\n",
    "    \n",
    "    logger.info('Starting the vol computation')\n",
    "    \n",
    "    results = pd.DataFrame(columns=['date', 'key', 'vol20', 'vol40'])\n",
    "    grouped = df.groupby('key')\n",
    "    \n",
    "    for key, group in grouped:\n",
    "        \n",
    "        logger.info(f'Computing standard deviations for key: {key}')\n",
    "        \n",
    "        group = group.sort_values('date')\n",
    "        \n",
    "        group['vol20'] = group['pnl'].rolling(window=20).std()\n",
    "        group['vol40'] = group['pnl'].rolling(window=40).std()\n",
    "        \n",
    "        results = pd.concat([results, group[['date', 'key', 'vol20', 'vol40']]])\n",
    "    \n",
    "    return results\n",
    "\n",
    "```\n",
    "\n",
    "#### 3.b Create a key column\n",
    "\n",
    "\n",
    "From within the GUI, create a column that is the concatenation of the stock and the porfolio.\n",
    "This will be the dimension of your PnL timeseries. Call it `timeseries_dimension`.\n",
    "\n",
    "\n",
    "#### 3.c Connect the script to your sheet\n",
    "\n",
    "Next, connect to your sheet and add the script in the control panel via the \"+ Controls\" > \"Button\".\n",
    "Make sure to bind the newly created `timeseries_dimension`, the TS time index (`date`) to the date input and the PNL.\n",
    "Save and run your script."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
