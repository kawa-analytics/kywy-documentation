{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9adb4ef4-39e0-4093-9f34-70f1774eb1d4",
   "metadata": {},
   "source": [
    "# Compute Volatility vol20 and vol40 using Python columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b89f7f87-8ac6-48b7-b616-714fcee8309d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Authentication successful on https://demo.kawa.ai:8080, in workspace 2\n"
     ]
    }
   ],
   "source": [
    "from kywy.client.kawa_client import KawaClient as K\n",
    "\n",
    "kawa = K.load_client_from_environment()\n",
    "cmd = kawa.commands"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "852af24b-1ae5-419b-986d-97e5f9a1d238",
   "metadata": {},
   "source": [
    "## 1. Dataset generation\n",
    "\n",
    "Let's generate a PnL timeseries with the following dimensions:\n",
    "- portfolio\n",
    "- stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a1c6105-2389-4e0e-a22f-4d0c7026641f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>portfolio</th>\n",
       "      <th>stock</th>\n",
       "      <th>date</th>\n",
       "      <th>pnl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>US_STOCKS</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>194.278174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>US_STOCKS</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>2014-01-02</td>\n",
       "      <td>191.622930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>US_STOCKS</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>2014-01-03</td>\n",
       "      <td>186.563538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>US_STOCKS</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>2014-01-04</td>\n",
       "      <td>201.000716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>US_STOCKS</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>2014-01-05</td>\n",
       "      <td>207.163552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40145</th>\n",
       "      <td>EU_STOCKS</td>\n",
       "      <td>LVMH</td>\n",
       "      <td>2023-12-25</td>\n",
       "      <td>157.511357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40146</th>\n",
       "      <td>EU_STOCKS</td>\n",
       "      <td>LVMH</td>\n",
       "      <td>2023-12-26</td>\n",
       "      <td>157.634141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40147</th>\n",
       "      <td>EU_STOCKS</td>\n",
       "      <td>LVMH</td>\n",
       "      <td>2023-12-27</td>\n",
       "      <td>158.508932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40148</th>\n",
       "      <td>EU_STOCKS</td>\n",
       "      <td>LVMH</td>\n",
       "      <td>2023-12-28</td>\n",
       "      <td>158.208550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40149</th>\n",
       "      <td>EU_STOCKS</td>\n",
       "      <td>LVMH</td>\n",
       "      <td>2023-12-29</td>\n",
       "      <td>158.008805</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40150 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       portfolio stock        date         pnl\n",
       "0      US_STOCKS  AAPL  2014-01-01  194.278174\n",
       "1      US_STOCKS  AAPL  2014-01-02  191.622930\n",
       "2      US_STOCKS  AAPL  2014-01-03  186.563538\n",
       "3      US_STOCKS  AAPL  2014-01-04  201.000716\n",
       "4      US_STOCKS  AAPL  2014-01-05  207.163552\n",
       "...          ...   ...         ...         ...\n",
       "40145  EU_STOCKS  LVMH  2023-12-25  157.511357\n",
       "40146  EU_STOCKS  LVMH  2023-12-26  157.634141\n",
       "40147  EU_STOCKS  LVMH  2023-12-27  158.508932\n",
       "40148  EU_STOCKS  LVMH  2023-12-28  158.208550\n",
       "40149  EU_STOCKS  LVMH  2023-12-29  158.008805\n",
       "\n",
       "[40150 rows x 4 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "data = []\n",
    "\n",
    "start_date = datetime.date(2014,1,1)\n",
    "day_count = 10 * 365\n",
    "\n",
    "# Define the different stocks in fictitious portfolios\n",
    "stocks = {\n",
    "        'US_STOCKS': ['AAPL','TSLA','MSFT','NVDA','INTC','GOOG','AMZN'],\n",
    "        'EU_STOCKS': ['BP','HSBC','ING', 'LVMH']   \n",
    "}\n",
    "\n",
    "# Define the normal distribution of the PnL for each stock to generate random data\n",
    "mu_sigma_per_stock = {\n",
    "    'AAPL': (200,5.1),\n",
    "    'TSLA': (170,8.1),\n",
    "    'MSFT': (432,0.3),\n",
    "    'NVDA': (120,10.2),\n",
    "    'INTC': (30,3.5),\n",
    "    'GOOG': (178,1.5),\n",
    "    'AMZN': (187,0.5),\n",
    "    'BP': (35,0.5),\n",
    "    'HSBC': (43,0.5),\n",
    "    'ING': (17,0.5),\n",
    "    'LVMH': (158,0.5),\n",
    "}\n",
    "\n",
    "# Generate the dataframe\n",
    "for portfolio, stock_list in stocks.items():\n",
    "    for stock in stock_list:\n",
    "        mu, sigma = mu_sigma_per_stock[stock]\n",
    "        pnl_list = np.random.normal(mu, sigma, day_count)\n",
    "        index = 0\n",
    "        for date in (start_date + datetime.timedelta(n) for n in range(day_count)):        \n",
    "            data.append({\n",
    "                'portfolio':portfolio,\n",
    "                'stock':stock,\n",
    "                'date': date,\n",
    "                'pnl':pnl_list[index],       \n",
    "            })\n",
    "            index+=1\n",
    "            \n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6365a139-63b1-4436-be75-7af21d4e2660",
   "metadata": {},
   "source": [
    "## 2. Ingest the generated data into KAWA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7dff1ba7-1e17-4962-9993-86a32040caf5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting an ingestion session with id=483f7a78-7068-4eed-ba02-4da1ce13f956\n",
      "> Exporting the dataframe into 2 parquet files\n",
      "> Starting 2 loading threads\n",
      "> Streaming file /var/folders/rl/6bqlws416nz6z2298zxq22zc0000gn/T/5b16b39f-dc12-42f6-b3c9-1a2b0c9cbf77/__partition__=1/2dab9b63d798425286fee6555f9b62cf-0.parquet to KAWA\n",
      "> Streaming file /var/folders/rl/6bqlws416nz6z2298zxq22zc0000gn/T/5b16b39f-dc12-42f6-b3c9-1a2b0c9cbf77/__partition__=0/2dab9b63d798425286fee6555f9b62cf-0.parquet to KAWA\n",
      "> 40150 rows were imported in 0.606295108795166ms\n",
      "> Import was successfully finalized\n",
      "Sheet PNL data was created: https://demo.kawa.ai:8080/workspaces/2/sheets/56/views/835\n"
     ]
    }
   ],
   "source": [
    "loader = kawa.new_data_loader(datasource_name='PNL data', df=df)\n",
    "loader.create_datasource()\n",
    "\n",
    "loader.load_data(\n",
    "    reset_before_insert=True,\n",
    "    create_sheet=True,\n",
    "    nb_threads=2\n",
    ");\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae4beac4-8640-4f2c-a417-c84a926c8c5f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 3. Create a Python column in KAWA\n",
    "\n",
    "#### 3.a Create the Python script\n",
    "\n",
    "Open the script section from your KAWA instance and create the following script\n",
    "\n",
    "\n",
    "```python\n",
    "import logging\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from kywy.client.kawa_decorators import outputs, inputs\n",
    "\n",
    "logger = logging.getLogger('script-logger')\n",
    "\n",
    "@inputs(key=str, date=datetime.date, pnl=float)\n",
    "@outputs(vol20=float, vol40=float)\n",
    "def execute(df: pd.DataFrame):\n",
    "    \n",
    "    logger.info('Starting the vol computation')\n",
    "    \n",
    "    results = pd.DataFrame(columns=['date', 'key', 'vol20', 'vol40'])\n",
    "    grouped = df.groupby('key')\n",
    "    \n",
    "    for key, group in grouped:\n",
    "        \n",
    "        logger.info(f'Computing standard deviations for key: {key}')\n",
    "        \n",
    "        group = group.sort_values('date')\n",
    "        \n",
    "        group['vol20'] = group['pnl'].rolling(window=20).std()\n",
    "        group['vol40'] = group['pnl'].rolling(window=40).std()\n",
    "        \n",
    "        results = pd.concat([results, group[['date', 'key', 'vol20', 'vol40']]])\n",
    "    \n",
    "    return results\n",
    "\n",
    "```\n",
    "\n",
    "#### 3.b Create a key column\n",
    "\n",
    "\n",
    "From within the GUI, create a column that is the concatenation of the stock and the porfolio.\n",
    "This will be the dimension of your PnL timeseries. Call it `timeseries_dimension`.\n",
    "\n",
    "\n",
    "#### 3.c Connect the script to your sheet\n",
    "\n",
    "Next, connect to your sheet and add the script in the control panel via the \"+ Controls\" > \"Button\".\n",
    "Make sure to bind the newly created `timeseries_dimension`, the TS time index (`date`) to the date input and the PNL.\n",
    "Save and run your script."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
